<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- <meta name="description"
        content="HyperNeRF handles topological variations by modeling a family of shapes in a higher-dimensional space, thereby producing more realistic renderings and more accurate geometric reconstructions.">
  <meta name="keywords" content="HyperNeRF, Nerfies, D-NeRF, NeRF"> -->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- <meta property="og:image" content="./static/images/thumbnail.png"/>
  <link rel="image_src" href="./static/images/thumbnail.png"> -->
  <!-- <link rel="icon"
        type="image/x-icon"
        href="./static/images/favicon.png"/> -->
  <link rel="icon" type="image/x-icon" href="assets/DoraemonGPT_logo.png">


  <title>DoraemonGPT</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-EDF010G6PN"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-EDF010G6PN');


  </script>

  <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
  <script type="text/javascript" src="https://code.jquery.com/jquery-1.11.0.min.js"></script>
  <script type="text/javascript" src="https://code.jquery.com/jquery-migrate-1.2.1.min.js"></script>
  <script src="https://unpkg.com/interactjs/dist/interact.min.js"></script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" type="text/css" href="./static/slick/slick.css" />
  <link rel="stylesheet" type="text/css" href="./static/slick/slick-theme.css" />

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
    .navbar {
      list-style-type: none;
      margin: 0;
      padding: 0;
      overflow: hidden;
      background-color: white;
      position: fixed;
      width: 100%;
      transition: background-color 0.5s ease; /* 为背景颜色改变添加过渡效果 */
    }

    .navbar.scrolled {
      background-color: #333;
    }

    .navbar li {
      float: left;
    }

    .navbar li a {
      display: block;
      color: black;
      text-align: center;
      padding: 14px 16px;
      text-decoration: none;
      transition: color 0.5s ease; /* 为文本颜色改变添加过渡效果 */
    }

    .navbar.scrolled li a {
      color: white;
    }

    /* .navbar li a:hover {
      background-color: #111;
    } */
  </style>

<script>
  window.onscroll = function() {
    var navbar = document.getElementById('navbar');
    if (window.pageYOffset > 0) {
      navbar.classList.add('scrolled');
    } else {
      navbar.classList.remove('scrolled');
    }
  }
</script>
</head>

<body>
  <ul class="navbar" id="navbar">
    <li><a href="#home"><img src="assets/DoraemonGPT_logo.png" alt="Home" style="height:30px; width:30px; vertical-align:middle; margin-right:5px;">  <strong>DoraemonGPT</strong> </a></li>
  </ul>
  
  <!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div> -->
  <!-- <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div> -->
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered">
          <!-- <div class="column is-4 has-text-centered">
          <img src="static/images/logo.svg" alt="HyperNeRF"/>
        </div> -->
        </div>
        <div class="container has-text-centered">
          <h1 class="title is-2 publication-title">
            <br>
            <a style="color: #479ee1;">DoraemonGPT</a>: Toward Understanding Dynamic Scenes </br> with Large Language Models </br> (Exemplified as A Video Agent)
          </h1>
          <div class="is-size-5 publication-authors">
            <div class="author-block">
              <a href="https://z-x-yang.github.io/" target="_blank">Zongxin Yang</a>,</div>
            <div class="author-block">
              <a href="https://scholar.google.com/citations?user=I1TOdpkAAAAJ&hl=en" target="_blank">Guikun Chen</a>,</div>
            <div class="author-block">
              <a href="https://scholar.google.com/citations?user=B-o8eCwAAAAJ" target="_blank">Xiaodi Li</a>,</div>
            <div class="author-block">
              <a href="https://sites.google.com/view/wenguanwang" target="_blank">Wenguan Wang</a>,</div>
            <div class="author-block">
              <a href="https://scholar.google.com/citations?user=RMSuNFwAAAAJ&hl=zh-CN&oi=ao" target="_blank">Yi Yang</a><sup>✉</sup></div>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">ReLER, CCAI, Zhejiang University</span>
          </div>
          <div class="is-size-5 publication-authors">
            <sup>✉</sup>Corresponding Author
          </div>
          <div class="is-size-5 publication-authors">
            <b>ICML 2024</b>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2401.08392"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2401.08392" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/z-x-yang/DoraemonGPT" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
  </section>

  <section class="hero teaser">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <center>
          <figure style="width: 100%;">
            <a>
              <img src="assets/overview.png">
            </a>
            <p class="caption" style="margin-bottom: 1px;  text-align: justify">
              <b>Overview.</b> Given a video with a question/task, DoraemonGPT first extracts a Task-related Symbolic Memory, which has two types of memory for selection: space-dominant memory based on instances and time-dominant memory based on time frames/clips. The memory can be queried by sub-task tools, which are driven by LLMs with different prompts and generate symbolic language (i.e., SQL sentences) to do different reasoning. Also, other tools for querying external knowledge or utility tools are supported. For planning, DoraemonGPT employs the MCTS Planner to decompose the question into an action sequence by exploring multiple feasible N solutions, which can be further summarized into an informative answer.
            </p>
          </figure>
        </center>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">

      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Recent LLM-driven visual agents mainly focus on solving image-based tasks, which limits their ability to understand dynamic scenes, making it far from real-life applications like guiding students in laboratory experiments and identifying their mistakes. Hence, this paper explores DoraemonGPT, a comprehensive and conceptually elegant system driven by LLMs to understand dynamic scenes. Considering the video modality better reflects the ever-changing nature of real-world scenarios, we exemplify DoraemonGPT as a video agent. Given a video with a question/task, DoraemonGPT begins by converting the input video into a symbolic memory that stores task-related attributes. This structured representation allows for spatial-temporal querying and reasoning by well-designed sub-task tools, resulting in concise intermediate results. Recognizing that LLMs have limited internal knowledge when it comes to specialized domains (e.g., analyzing the scientific principles underlying experiments), we incorporate plug-and-play tools to assess external knowledge and address tasks across different domains. Moreover, a novel LLM-driven planner based on Monte Carlo Tree Search is introduced to explore the large planning space for scheduling various tools. The planner iteratively finds feasible solutions by backpropagating the result's reward, and multiple solutions can be summarized into an improved final answer. We extensively evaluate DoraemonGPT's effectiveness on three benchmarks and several in-the-wild scenarios.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <center>
          <h2 class="title is-3">In-the-wile Example — Inspection of Experiment</h2>
          <video id="teaser" autoplay controls muted loop playsinline height="100%">
            <source src="./assets/demo1.mp4" type="video/mp4">
          </video>
          <figure style="width: 100%;">
            <!-- <a>
              <img src="assets/itw_1.png">
            </a> -->
            <p class="caption" style="margin-bottom: 1px;  text-align: justify">
              An in-the-wild example of DoraemonGPT. Given a video input and a question, our system automatically explores the solution space powered by MCTS planner and various tools. This figure demonstrates both the utilized tools, and the result of intermediate steps during the exploration. Taking advantage of the tree-like exploration paths, DoraemonGPT can not only summarize collected answers into a better one, but also has the potential to generate multiple potential solutions.
            </p>
          </figure>
        </center>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <center>
          <h2 class="title is-3">Qualitative Result — Referring Object Segmentation</h2>
          <video id="teaser" autoplay controls muted loop playsinline height="100%">
            <source src="./assets/demo3.mp4" type="video/mp4">
          </video>
        </center>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <center>
          <h2 class="title is-3">In-the-wile Example — Video Editing</h2>
          <video id="teaser" autoplay controls muted loop playsinline height="100%">
            <source src="./assets/demo2.mp4" type="video/mp4">
          </video>
        </center>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <center>
          <h2 class="title is-3">In-the-wile Example — Video Understanding</h2>
          <video id="teaser" autoplay controls muted loop playsinline height="100%">
            <source src="./assets/demo4.mp4" type="video/mp4">
          </video>
        </center>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <center>
          <h2 class="title is-3">Qualitative Result — Video Question Answering</h2>
          <video id="teaser" autoplay controls muted loop playsinline height="100%">
            <source src="./assets/demo5.mp4" type="video/mp4">
          </video>
          <!-- <figure style="width: 100%;">
            <a>
              <img src="assets/qualitative_1.png">
            </a>
            <p class="caption" style="margin-bottom: 1px;  text-align: justify">
              XX
            </p>
          </figure> -->
        </center>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <center>
          <h2 class="title is-3">Quantitative Result — Video Question Answering</h2>
          <center>
            <figure style="width: 60%;">
              <a>
                <img src="assets/res_vqa.png">
              </a>
            </figure>
          </center>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <center>
          <h2 class="title is-3">Quantitative Result — Referring Object Segmentation</h2>
          <figure style="width: 52%;">
            <a>
              <img src="assets/res_ros.png">
            </a>
          </figure>
          </center>
        </div>
      </div>
    </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container content is-max-desktop">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{yang2024doraemongpt,
    title={Doraemongpt: Toward understanding dynamic scenes with large language models (exemplified as a video agent)},
    author={Yang, Zongxin and Chen, Guikun and Li, Xiaodi and Wang, Wenguan and Yang, Yi},
    booktitle={ICML},
    year={2024},
}
</code></pre>
    </div>
  </section>


    <footer class="footer">
      <div class="container">
        <!-- <div class="content has-text-centered">
          <a class="icon-link" href="https://openreview.net/pdf?id=o3yygm3lnzS">
            <i class="fas fa-file-pdf"></i>
          </a>
          <a class="icon-link" href="https://github.com/bytedance/pv3d" class="external-link" disabled>
            <i class="fab fa-github"></i>
          </a>
        </div> -->
        <div class="columns is-centered">
          <div class="column is-6">
            <div class="content">
              <p>
                The source code of this webpage is based on the <a href="https://github.com/nerfies/nerfies.github.io/">
                  Nerfies</a> project webpage.
              </p>
            </div>
          </div>
        </div>
      </div>
    </footer>

    <script type="text/javascript" src="./static/slick/slick.min.js"></script>
</body>

</html>
